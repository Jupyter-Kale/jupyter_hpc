{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bqplot as bq\n",
    "import networkx\n",
    "import numpy as np\n",
    "import ipywidgets as ipw\n",
    "from copy import copy, deepcopy\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bq.Graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With indices as dag nodes\n",
    "\n",
    "class Workflow(object):\n",
    "    def __init__(self, name):\n",
    "        self.dag = networkx.graph.Graph()\n",
    "        self.name = name\n",
    "        self.index_dict = {}\n",
    "        #self.fig_layout = ipw.Layout(width='600px', height='800px')\n",
    "        self.fig_layout = ipw.Layout(width='1000px', height='800px')\n",
    "        self._task_names = []\n",
    "    \n",
    "    def add_task(self, task, dependencies=None):\n",
    "        \"\"\"\n",
    "        Add instantiated Task object to the Workflow.\n",
    "        If dependencies=None, then this task will be executed\n",
    "        as soon as possible upon starting the Workflow.\n",
    "        A Task may appear only once per Workflow.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Ensure that tasks are not repeated.\n",
    "        if task in self.dag.nodes():\n",
    "            raise ValueError(\"Task already present in Workflow. Please pass a deepcopy if you wish to repeat the Task.\")\n",
    "        elif task.name in self._task_names:\n",
    "            raise ValueError(\"Task name '{}' already present in Workflow. Please use a unique name.\".format(task.name))\n",
    "            \n",
    "        # Determine index for this Task in this Workflow\n",
    "        index = self.dag.number_of_nodes()\n",
    "        # Inform workflow and task of this assignment\n",
    "        self.dag.add_node(task, index=index)\n",
    "        task.index[self] = index\n",
    "        \n",
    "        if dependencies is not None:\n",
    "            for dependency in dependencies:\n",
    "                self.dag.add_edge(dependency, task)\n",
    "                \n",
    "    def get_task_by_name(self, name):\n",
    "        \"Return the Task object with the given name in this Workflow.\"\n",
    "        for task in self.dag.nodes():\n",
    "            try:\n",
    "                if task.name == name:\n",
    "                    return task\n",
    "            except AttributeError:\n",
    "                print(\"{} has no name.\".format(task))\n",
    "\n",
    "    def _gen_bqgraph(self):\n",
    "        \"Generate bqplot graph.\"\n",
    "        \n",
    "        pos = networkx.nx_pydot.graphviz_layout(self.dag, prog='dot')\n",
    "        N = self.dag.number_of_nodes()\n",
    "        \n",
    "        x, y = [[pos[node][i] for node in self.dag.nodes()] for i in range(2)]\n",
    "\n",
    "        node_data = [\n",
    "            {\n",
    "                'label': str(node.index[self]),\n",
    "                'shape': 'rect',\n",
    "                **node.get_user_dict()\n",
    "            }\n",
    "            for node in self.dag.nodes()\n",
    "        ]\n",
    "        link_data = [\n",
    "            {\n",
    "                'source': source.index[self],\n",
    "                'target': target.index[self]\n",
    "            } \n",
    "            for source, target in self.dag.edges()\n",
    "        ]\n",
    "\n",
    "        xs = bq.LinearScale()\n",
    "        ys = bq.LinearScale()\n",
    "        scales = {'x': xs, 'y': ys}\n",
    "        \n",
    "        graph = bq.Graph(\n",
    "            node_data=node_data,\n",
    "            link_data=link_data,\n",
    "            scales=scales,\n",
    "            link_type='line',\n",
    "            highlight_links=False,\n",
    "            x=x, y=y,\n",
    "            selected_style={'stroke':'red'}\n",
    "            #interactions = {\n",
    "            #    'click': 'tooltip',\n",
    "            #    'hover': 'select'\n",
    "            #},\n",
    "        )\n",
    "        \n",
    "        # graph.tooltip = bq.Tooltip(\n",
    "        #     fields=self.dag.nodes()[0].user_fields\n",
    "        # )\n",
    "        \n",
    "        return graph\n",
    "    \n",
    "    def get_bqgraph(self):\n",
    "        \"Retrieve, but do not regenerate bqplot graph.\"\n",
    "        return self._bqgraph\n",
    "    \n",
    "    def draw_dag(self, layout=None):\n",
    "        \"Return bqplot figure representing DAG, regenerating graph.\"\n",
    "        \n",
    "        self._bqgraph = self._gen_bqgraph()\n",
    "        \n",
    "        graph = self.get_bqgraph()\n",
    "        if layout == None:\n",
    "            layout = self.fig_layout\n",
    "            \n",
    "        fig = bq.Figure(marks=[graph], layout=layout)\n",
    "                        \n",
    "        toolbar = bq.Toolbar(figure=fig)\n",
    "        \n",
    "        return ipw.VBox([fig, toolbar])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Task(object):\n",
    "    \"One step in a Workflow. Must have a unique name.\"\n",
    "    def __init__(self, name, input_files=[], output_files=[], \n",
    "                 params={}, num_cores=1, task_type='',\n",
    "                substitute_strings=[], substitute_lists=[],\n",
    "                user_fields=[]):\n",
    "        \n",
    "        # Name of task (must be unique)\n",
    "        self.name = name\n",
    "        \n",
    "        # Type of task (Notebook, CommandLine, etc.)\n",
    "        self.task_type = task_type\n",
    "        \n",
    "        # List of other Tasks which must complete \n",
    "        # before this Task can be run.\n",
    "        self.dependencies = []\n",
    "        \n",
    "        # List of Tasks which depend on this Task.\n",
    "        self.children = []\n",
    "        \n",
    "        # Files which this Task takes as input \n",
    "        # and must be present before run.\n",
    "        self.input_files = input_files\n",
    "        \n",
    "        # Files which are generated or modified by this Taks.\n",
    "        self.output_files = output_files\n",
    "        \n",
    "        # Number of CPU cores to run the task on\n",
    "        self.num_cores = num_cores\n",
    "        \n",
    "        # Map workflow to the node index which\n",
    "        # represents this task in that workflow.\n",
    "        # Tasks may be in multiple workflows,\n",
    "        self.index = {}\n",
    "        \n",
    "        # Parameters to replace in other arguments\n",
    "        self.params = params\n",
    "        \n",
    "        # List of names of fields to substitute params.\n",
    "        # If a child class calls Task.__init__ with\n",
    "        # substitute_strings or substitute_lists as\n",
    "        # nonempty lists, they will be included here.\n",
    "        self._substitute_strings = [\n",
    "            'name',\n",
    "            'task_type'\n",
    "        ] + substitute_strings\n",
    "        self._substitute_lists = [\n",
    "            'input_files',\n",
    "            'output_files'\n",
    "        ] + substitute_lists\n",
    "        \n",
    "        self._substitute_fields()\n",
    "        \n",
    "        # Fields which are of interest to the user\n",
    "        self.user_fields = [\n",
    "            'name', \n",
    "            'task_type', \n",
    "            'input_files', \n",
    "            'output_files',\n",
    "            'num_cores'\n",
    "        ] + user_fields\n",
    "    \n",
    "    def get_user_dict(self):\n",
    "        \"Generate dictionary of user field names and values\"\n",
    "        return {\n",
    "            field: getattr(self, field) \n",
    "            for field in self.user_fields\n",
    "        }\n",
    "            \n",
    "    def _substitute_fields(self):\n",
    "        \"Replace fields according to params dict.\"\n",
    "        for field in self._substitute_strings:\n",
    "            # Read current value\n",
    "            before = getattr(self,field)\n",
    "            # Replace fields\n",
    "            after = before.format(**self.params)\n",
    "            # Write new value\n",
    "            setattr(self, field, after)\n",
    "            \n",
    "        for list_name in self._substitute_lists:\n",
    "            field_list = getattr(self, list_name)\n",
    "            # Read current values\n",
    "            for i, before in enumerate(field_list):\n",
    "                # Replace fields\n",
    "                after = before.format(**self.params)\n",
    "                # Write to working copy of list\n",
    "                field_list[i] = after\n",
    "            # Write working copy to actual list\n",
    "            setattr(self, list_name, field_list)\n",
    "                \n",
    "    def _run(self):\n",
    "        \"\"\"\n",
    "        Run this Task. Should be executed by a Workflow.\n",
    "        This function should be overloaded by child classes.\n",
    "        \"\"\"\n",
    "        print(\"Task run.\")\n",
    "        \n",
    "\n",
    "class NotebookTask(Task):\n",
    "    \"\"\"\n",
    "    \n",
    "    Jupyter Notebook which should appear as a node in the Workflow DAG.\n",
    "    If interactive == True, a kernel will be started and the\n",
    "    notebook will be opened for user to interact with.\n",
    "    Workflow will be blocked in the meantime.\n",
    "    If false, notebook will be executed without opening,\n",
    "    and Workflow will continue upon successful execution.\n",
    "    \"\"\"\n",
    "    def __init__(self, name, interactive=True, **kwargs):\n",
    "        self.task_type = 'NotebookTask'\n",
    "        self.interactive = interactive\n",
    "        \n",
    "        user_fields = ['interactive']\n",
    "        \n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            user_fields=user_fields,\n",
    "            **kwargs)\n",
    "    \n",
    "    def _run(self):\n",
    "        print(\"Notebook run.\")\n",
    "    \n",
    "    def _unblock(self):\n",
    "        \"\"\"\n",
    "        Return control to Workflow after interactive notebook\n",
    "        execution is complete.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    \n",
    "class CommandLineTask(Task):\n",
    "    \"Command Line Task to be executed as a Workflow step.\"\n",
    "    def __init__(self, name, command, **kwargs):\n",
    "        \n",
    "        self.command = command\n",
    "        \n",
    "        user_fields = ['command']\n",
    "        \n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            task_type='CommandLineTask',\n",
    "            substitute_strings=['command'],\n",
    "            user_fields=user_fields,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def _run(self):\n",
    "        print(\"Command Line run.\")\n",
    "\n",
    "        \n",
    "class PythonFunctionTask(Task):\n",
    "    \"Python function call to be executed as a Workflow step.\"\n",
    "    def __init__(self, name, fun, fun_args, fun_kwargs, **kwargs):\n",
    "        # Actual callable function to be executed.\n",
    "        self.fun = fun\n",
    "        \n",
    "        user_fields = ['fun_args', 'fun_kwargs']\n",
    "        \n",
    "        super().__init__(\n",
    "            name=name, \n",
    "            task_type='PythonFunctionTask',\n",
    "            user_fields=user_fields,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    def _run(self):\n",
    "        print(\"Python function run.\")\n",
    "        return self.fun(*fun_args, **fun_kwargs)\n",
    "    \n",
    "class BatchTask(Task):\n",
    "    \"Task which will be submitted to a batch queue to execute.\"\n",
    "    def __init__(self, name, batch_script, **kwargs):\n",
    "        self.batch_script = batch_script\n",
    "        \n",
    "        user_fields = ['batch_script']\n",
    "        \n",
    "        super().__init__(\n",
    "            name=name, \n",
    "            task_type='BatchTask',\n",
    "            user_fields=user_fields,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    def _run(self):\n",
    "        print(\"Batch run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Droplet Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "droplet_wf = Workflow('Droplet Workflow')\n",
    "\n",
    "# Radius of droplets (Angstroms)\n",
    "droplet_radii = [20,30,40,50,60,100]\n",
    "# Shape of droplets\n",
    "shape = 'sphere'\n",
    "# Base directory for computations\n",
    "base_dir = '$SCRATCH/droplet'\n",
    "\n",
    "# Number of substrate images in each dimension\n",
    "nx, ny = 10, 10\n",
    "\n",
    "# Number of parts (dump files) per simulation\n",
    "parts_per_sim = 8\n",
    "\n",
    "# Generate substrate\n",
    "gen_mica_task = CommandLineTask(\n",
    "    name='gen_mica_{nx}x{ny}',\n",
    "    command='{base_dir}/gen_droplet/scripts/gen_mica.sh {nx} {ny} {out_file}',\n",
    "    output_files = [\n",
    "        \"{out_file}\"\n",
    "    ],\n",
    "    params=dict(\n",
    "        base_dir=base_dir,\n",
    "        nx=nx,\n",
    "        ny=ny,\n",
    "        out_file=\"{base_dir}/gen_droplet/lammps_data/mica_{nx}x{ny}.data\".format(\n",
    "            base_dir=base_dir,\n",
    "            nx=nx,\n",
    "            ny=ny\n",
    "        )\n",
    "    )\n",
    ")\n",
    "droplet_wf.add_task(gen_mica_task)\n",
    "\n",
    "# Loop over droplet sizes\n",
    "for radius in droplet_radii:\n",
    "    # Create droplet\n",
    "    gen_droplet_task = CommandLineTask(\n",
    "        name=\"gen_droplet-{radius}A\",\n",
    "        command=\"{base_dir}/gen_droplet/bin/waterdroplet_tip4p_new.out {radius} {shape}\",\n",
    "        output_files = [\n",
    "            \"{out_file}\"\n",
    "        ],\n",
    "        params=dict(\n",
    "            base_dir=base_dir,\n",
    "            radius=radius,\n",
    "            shape=shape,\n",
    "            out_file=\"{base_dir}/gen_droplet/dump/droplet_{radius}A.lammpstrj\".format(\n",
    "                base_dir=base_dir,\n",
    "                radius=radius\n",
    "            )\n",
    "        )\n",
    "    )      \n",
    "    droplet_wf.add_task(gen_droplet_task)\n",
    "    \n",
    "    # Combine with substrate\n",
    "    combine_task = CommandLineTask(\n",
    "        name=\"combine-{radius}A\",\n",
    "        command=\"{base_dir}/gen_droplet/scripts/combine_sub_strip.pl {substrate} {film} {gap}\",\n",
    "        input_files = [\n",
    "            \"{substrate}\",\n",
    "            \"{film}\"\n",
    "        ],\n",
    "        output_files = [\n",
    "            \"{base_dir}/gen_droplet/lammps_data/droplet_on_mica-{radius}A.data\"\n",
    "        ],\n",
    "        params=dict(\n",
    "            base_dir=base_dir,\n",
    "            radius=radius,\n",
    "            substrate=gen_mica_task.output_files[0],\n",
    "            film=gen_droplet_task.output_files[0],\n",
    "            gap=radius,\n",
    "        )\n",
    "    )\n",
    "    droplet_wf.add_task(\n",
    "        combine_task,\n",
    "        dependencies=[\n",
    "            gen_mica_task,\n",
    "            gen_droplet_task\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    simulate_task = BatchTask(\n",
    "        name=\"simulate-{radius}A\",\n",
    "        batch_script=\"{base_dir}/sub_scripts/simulate_{radius}A.batch\",\n",
    "        input_files = [\n",
    "            combine_task.output_files[0],\n",
    "            \"{base_dir}/lammps_scripts/simulate_{radius}A.batch\"\n",
    "        ],\n",
    "        output_files = [\n",
    "            \"{base_dir}/data/{radius}A/atom\"+str(part)\n",
    "            for part in range(1,parts_per_sim+1)\n",
    "        ],\n",
    "        num_cores=parts_per_sim,\n",
    "        params=dict(\n",
    "            base_dir=base_dir,\n",
    "            radius=radius,\n",
    "        )\n",
    "    )\n",
    "    droplet_wf.add_task(\n",
    "        simulate_task,\n",
    "        dependencies=[combine_task]\n",
    "    )\n",
    "    \n",
    "    # Analyze each part independently\n",
    "    for part in range(1,parts_per_sim+1):\n",
    "        parse_task = CommandLineTask(\n",
    "            name='parse-{radius}A_atom{part}',\n",
    "            command='{base_dir}/exec/parse.sh {infile} {outfile}',\n",
    "            input_files = [\"{infile}\"],\n",
    "            output_files = [\"{outfile}\"],\n",
    "            params=dict(\n",
    "                base_dir=base_dir,\n",
    "                radius=radius,\n",
    "                part=part,\n",
    "                infile=simulate_task.output_files[part-1],\n",
    "                outfile=\"{base_dir}/results/{radius}A/waters.txt\".format(\n",
    "                    base_dir=base_dir,\n",
    "                    radius=radius\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        droplet_wf.add_task(\n",
    "            parse_task,\n",
    "            dependencies=[simulate_task]\n",
    "        )\n",
    "        \n",
    "        analyze_task = CommandLineTask(\n",
    "            name='analyze-{radius}A_atom{part}',\n",
    "            command='{base_dir}/exec/analyze.sh {infile} {outfile}',\n",
    "            input_files = [\"{infile}\"],\n",
    "            output_files = [\"{outfile}\"],\n",
    "            params=dict(\n",
    "                base_dir=base_dir,\n",
    "                radius=radius,\n",
    "                part=part,\n",
    "                infile=parse_task.output_files[0],\n",
    "                outfile=\"{base_dir}/results/{radius}A/calculated.txt\".format(\n",
    "                    base_dir=base_dir,\n",
    "                    radius=radius\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        droplet_wf.add_task(\n",
    "            analyze_task,\n",
    "            dependencies=[parse_task]\n",
    "        )\n",
    "    \n",
    "    combine_parts_task = CommandLineTask(\n",
    "        name='combine_parts-{radius}A',\n",
    "        command='{base_dir}/results/combineParts.sh {radius}A',\n",
    "        input_files = [\n",
    "            \"{base_dir}/results/{radius}A/atom\"+str(part)+\"/calculated.txt\"\n",
    "            for part in range(1,parts_per_sim+1)\n",
    "        ],\n",
    "        output_files=[\"{base_dir}/results/{radius}A/combined.txt\"],\n",
    "        params=dict(\n",
    "            base_dir=base_dir,\n",
    "            radius=radius,\n",
    "        )\n",
    "    )\n",
    "    droplet_wf.add_task(\n",
    "        combine_parts_task,\n",
    "        dependencies=[droplet_wf.get_task_by_name(\n",
    "            'analyze-{radius}A_atom{part}'.format(\n",
    "                radius=radius,\n",
    "                part=part\n",
    "            )\n",
    "        )\n",
    "        for part in range(1,parts_per_sim+1)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "combine_sims_task = CommandLineTask(\n",
    "    name='combine_sims',\n",
    "    command='{base_dir}/results/combineSims.sh',\n",
    "    input_files = [\n",
    "        \"{base_dir}/results/\"+str(radius)+\"A/combined.txt\"\n",
    "        for radius in droplet_radii\n",
    "    ],\n",
    "    output_files=[\"{base_dir}/results/allResults.txt\"],\n",
    "    params=dict(base_dir=base_dir)\n",
    ")\n",
    "droplet_wf.add_task(\n",
    "    combine_sims_task,\n",
    "    dependencies=[\n",
    "        droplet_wf.get_task_by_name(\n",
    "            'combine_parts-{radius}A'.format(\n",
    "                radius=radius\n",
    "            )\n",
    "        )\n",
    "        for radius in droplet_radii\n",
    "    ]\n",
    ")\n",
    "analysis_notebook_task = NotebookTask(\n",
    "    name='analysis_notebook',\n",
    "    interactive=True,\n",
    ")\n",
    "droplet_wf.add_task(\n",
    "    analysis_notebook_task,\n",
    "    dependencies=[combine_sims_task]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38cb5662daf64e8889050431f749f655",
       "version_major": "2",
       "version_minor": "0"
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = droplet_wf.draw_dag()\n",
    "#tb = bq.Toolbar(figure=fig)\n",
    "#q = display(fig,tb)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.layout.width=u'400px'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig.children[0].marks[0].selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow GUI Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EditHTML(ipw.VBox):\n",
    "    def __init__(self, value='', text_height=400):\n",
    "        super().__init__()\n",
    "        self.HTML = ipw.HTMLMath(value=value)\n",
    "        self.Text = ipw.Textarea(value=value)\n",
    "        self.ToggleButton = ipw.Button(description='Toggle')\n",
    "        \n",
    "        self.elements = [self.HTML, self.Text]\n",
    "        self.descriptions = ['Edit', 'Render']\n",
    "        ipw.jslink((self.HTML, 'value'), (self.Text, 'value'))\n",
    "        \n",
    "        # Set height and width of Textarea\n",
    "        self.Text.layout.height = u'{}px'.format(text_height)\n",
    "        self.Text.layout.width = u'95%'\n",
    "        \n",
    "        # Set HTML view by default\n",
    "        self.set_view(0)\n",
    "        \n",
    "        self.ToggleButton.on_click(self.toggle)\n",
    "    \n",
    "    def set_view(self, state):\n",
    "        self.state = state\n",
    "        self.children = [self.elements[state], self.ToggleButton]\n",
    "        self.ToggleButton.description = self.descriptions[state]\n",
    "        \n",
    "    def toggle(self, caller):\n",
    "        self.set_view((self.state+1)%2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WorkflowWidget(ipw.HBox):\n",
    "    \"Widget to draw DAG via bqplot and provide node-level info/interaction.\"\n",
    "    \n",
    "    @property\n",
    "    def bqgraph(self):\n",
    "        return self.workflow.get_bqgraph()\n",
    "    \n",
    "    def __init__(self, workflow):\n",
    "        super(WorkflowWidget, self).__init__()\n",
    "        \n",
    "        # Define variables\n",
    "        self.workflow = workflow\n",
    "        self._fig_layout = ipw.Layout(width='400px', height='600px')\n",
    "        self._xs = bq.LinearScale()\n",
    "        self._ys = bq.LinearScale()\n",
    "        self._scales = {'x': self._xs, 'y': self._ys}\n",
    "        mgin = 10\n",
    "        \n",
    "        # Define elements\n",
    "        self._metadata_template = \"\"\"\n",
    "        Node name: {name}\n",
    "        <br>\n",
    "        Last modified: {date}\n",
    "        <br>\n",
    "        Description: {word}\n",
    "        \"\"\"\n",
    "        self._metadata_html = ipw.HTML()\n",
    "        \n",
    "        readme_html = EditHTML(r\"\"\"\n",
    "            <h1>Radiative Transfer</h1>\n",
    "\n",
    "            The Radiative Transfer Equation is given by\n",
    "\n",
    "            <p>\n",
    "            $$\\nabla I \\cdot \\omega = -c\\, I(x, \\omega) + \\int_\\Omega \\beta(|\\omega-\\omega'|)\\, I(x, \\omega')$$\n",
    "            </p>\n",
    "\n",
    "            It is useful for\n",
    "            <ul>\n",
    "            <li>\n",
    "            Stellar astrophysics\n",
    "            </li>\n",
    "            <li>\n",
    "            Kelp\n",
    "            </li>\n",
    "            <li>\n",
    "            Nice conversations\n",
    "            </li>\n",
    "            </ul>\n",
    "\n",
    "            And is explained well by the following diagram.\n",
    "            <br />\n",
    "            <br />\n",
    "            <img width=300px src=\"http://soap.siteturbine.com/uploaded_files/www.oceanopticsbook.info/images/WebBook/0dd27b964e95146d0af2052b67c7b5df.png\" />\n",
    "        \"\"\")\n",
    "        self._notebook_button = ipw.Button(\n",
    "            description='Open Notebook',\n",
    "            button_style='success'\n",
    "        )\n",
    "        self._log_path_input = ipw.Text(\n",
    "            description='Log path',\n",
    "            value='/etc/login.defs'\n",
    "        )\n",
    "        self._log_html = ipw.HTML()\n",
    "        \n",
    "        self._readme_area = ipw.VBox([\n",
    "            readme_html\n",
    "        ])\n",
    "        self._info_area = ipw.VBox([\n",
    "            self._notebook_button,\n",
    "            self._metadata_html\n",
    "        ])\n",
    "        self._log_area = ipw.VBox([\n",
    "            self._log_path_input,\n",
    "            self._log_html\n",
    "        ])\n",
    "        \n",
    "        self._graph_container = workflow.draw_dag(layout=self._fig_layout)\n",
    "        self._graph_figure = self._graph_container.children[0]\n",
    "        \n",
    "        self._tab = ipw.Tab([\n",
    "            self._readme_area,\n",
    "            self._info_area,\n",
    "            self._log_area\n",
    "        ])\n",
    "        \n",
    "        self.output_area = ipw.Output()\n",
    "        \n",
    "        # Define layout\n",
    "        self.children = [\n",
    "            self._graph_container,\n",
    "            self._tab,\n",
    "        ]\n",
    "        \n",
    "        # Set attributes\n",
    "        self._tab.set_title(0, 'Readme')\n",
    "        self._tab.set_title(1, 'Info')\n",
    "        self._tab.set_title(2, 'Log')\n",
    "        self._tab.layout.height = self._fig_layout.height\n",
    "        self._tab.layout.width = self._fig_layout.width\n",
    "        \n",
    "        #self._graph_figure.layout.border = '3px red solid'\n",
    "        self._graph_figure.fig_margin = dict(\n",
    "            left=mgin,\n",
    "            right=mgin,\n",
    "            bottom=mgin,\n",
    "            top=mgin\n",
    "        )\n",
    "        self._graph_figure.min_aspect_ratio = 0\n",
    "        \n",
    "        # Graph style\n",
    "        self.bqgraph.selected_style = dict(\n",
    "            stroke='red'\n",
    "        )\n",
    "        \n",
    "        # Default selections\n",
    "        self._tab.selected_index = 0\n",
    "        self.bqgraph.selected = [0]\n",
    "        \n",
    "        # Logic\n",
    "        self.bqgraph.observe(self._call_update_metadata_html, names='selected')\n",
    "        self._log_path_input.on_submit(self._call_read_log)\n",
    "        \n",
    "        # Run updates\n",
    "        self._call_read_log()\n",
    "    \n",
    "    def _update_metadata_html(self, metadata):\n",
    "        html = \"<br>\".join([\n",
    "            \"\"\"\n",
    "            <b>{key}:</b> {value}\n",
    "            \"\"\".format(\n",
    "                key=key,\n",
    "                value=value\n",
    "                )\n",
    "            for key,value in metadata.items()\n",
    "        ])\n",
    "        \n",
    "        with self.output_area:\n",
    "            print(html)\n",
    "        \n",
    "        self._metadata_html.value = html\n",
    "        \n",
    "       \n",
    "    def _call_update_metadata_html(self, change):\n",
    "        # Newly selected node (workflow step)\n",
    "        # (Only take first if several are selected)\n",
    "        \n",
    "        if change['new'] is None:\n",
    "            metadata = {}\n",
    "            \n",
    "        else:\n",
    "            node_num = change['new'][0]\n",
    "\n",
    "            node = self.workflow.dag.nodes()[node_num]\n",
    "\n",
    "            with self.output_area:\n",
    "                print(\"Selected node {}\".format(node_num))\n",
    "\n",
    "            metadata = {\n",
    "                attr: getattr(node, attr)\n",
    "                for attr in node.user_fields\n",
    "            }\n",
    "\n",
    "        self._update_metadata_html(metadata)\n",
    "\n",
    "    def _read_log(self, log_path):\n",
    "        try:\n",
    "            with open(log_path) as log_file:\n",
    "                log_text = log_file.read()\n",
    "        except IOError:\n",
    "            log_text = 'Error opening {}'.format(log_path)\n",
    "        \n",
    "        self._log_html.value = log_text\n",
    "    \n",
    "    def _call_read_log(self, caller=None):\n",
    "        log_path = self._log_path_input.value\n",
    "        self._read_log(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81d8a613b384a4eb63ed4dd17e039c8",
       "version_major": "2",
       "version_minor": "0"
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = WorkflowWidget(droplet_wf)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.bqgraph.selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droplet_wf.dag.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b702b29f19d6407a9d5c27e19a08ba85",
       "version_major": "2",
       "version_minor": "0"
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w.output_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_files': [],\n",
       " 'label': '0',\n",
       " 'name': 'gen_mica_10x10',\n",
       " 'num_cores': 1,\n",
       " 'output_files': ['$SCRATCH/droplet/gen_droplet/lammps_data/mica_10x10.data'],\n",
       " 'shape': 'rect',\n",
       " 'task_type': 'CommandLineTask'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.bqgraph.node_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_substitute_lists': ['input_files', 'output_files'],\n",
       " '_substitute_strings': ['name', 'task_type', 'command'],\n",
       " 'children': [],\n",
       " 'command': '$SCRATCH/droplet/gen_droplet/scripts/gen_mica.sh 10 10 $SCRATCH/droplet/gen_droplet/lammps_data/mica_10x10.data',\n",
       " 'dependencies': [],\n",
       " 'index': {<__main__.Workflow at 0x2aab22f8e278>: 0},\n",
       " 'input_files': [],\n",
       " 'name': 'gen_mica_10x10',\n",
       " 'num_cores': 1,\n",
       " 'output_files': ['$SCRATCH/droplet/gen_droplet/lammps_data/mica_10x10.data'],\n",
       " 'params': {'base_dir': '$SCRATCH/droplet',\n",
       "  'nx': 10,\n",
       "  'ny': 10,\n",
       "  'out_file': '$SCRATCH/droplet/gen_droplet/lammps_data/mica_10x10.data'},\n",
       " 'task_type': 'CommandLineTask',\n",
       " 'user_fields': ['name',\n",
       "  'task_type',\n",
       "  'input_files',\n",
       "  'output_files',\n",
       "  'num_cores']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.workflow.dag.nodes()[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = w._graph_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'combine-20A'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.workflow.dag.nodes()[2].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_files': ['$SCRATCH/droplet/gen_droplet/lammps_data/mica_10x10.data',\n",
       "  '$SCRATCH/droplet/gen_droplet/dump/droplet_20A.lammpstrj'],\n",
       " 'label': '2',\n",
       " 'name': 'combine-20A',\n",
       " 'num_cores': 1,\n",
       " 'output_files': ['$SCRATCH/droplet/gen_droplet/lammps_data/droplet_on_mica-20A.data'],\n",
       " 'shape': 'rect',\n",
       " 'task_type': 'CommandLineTask'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.bqgraph.node_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-78d40fde49fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "n.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.scale_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "droplet_wf.get_bqgraph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
